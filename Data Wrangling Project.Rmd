---
title: "Capstone Data Wrangling"
author: "Simone Zanetti"
date: "10/5/2018"
output: html_document
---

```{r}
library(tidyr)
library(dplyr)
library(chron)
library(ggplot2)
library(ggmap)
```

```{r}
data_clean <- 
```
              
# ERASE THE FIRST ROW THAT IS NOT RELEVANT TO MY DATASET
```{r}
data_clean <- data_clean[-1,]
```

----------------------------------------

# 1. CHANGE NAME OF EACH VARIABLE TO MAKE THEM UNDERSTABLE
```{r}
data_clean <- data_clean %>% rename( "dep_to_bs" = `DATA PART`,
                                     "arr_to_bs" = `DATA ARR`,
                                     "delivery_day" = `DATA CONS`,
                                     "sender_who" = MITT,
                                     "addresser_who" = DITTA,
                                     "address_delivery"= IND,
                                     "district_delivery" = LOC,
                                     "weight_pack" = PESO,        
                                     "num_pack"= COLLI,
                                     "driver_code" = CODICE,
                                     "pickup_who"= FIRMA,
                                     "pickup_time" = ORA)
```

## Uniform each name to Lower character

```{r}
data_clean <- data_clean %>% 
              mutate_all(funs(tolower(.)))
```


----------------------------------------

# 2. DEALING WITH MISSING VALUES

I provide an *overwiew of which variables contain missing values* and *how many* creating a temporary variable useful for the analysis.
```{r}
missing_values <- data_clean %>% summarise_all(funs(sum(is.na(.)))) %>% gather(variable, num_NA) 
```

Once I identified which variables contain missing values I decide how to manage them:

**1. addressee_who**
```{r}
data_clean %>% filter(is.na(addresser_who))      #in order to check which rows contain NA in the variable and decide how to manage it
data_clean <- data_clean %>%  mutate(addresser_who = replace(addresser_who,is.na(addresser_who), "UNKNOWN"))
```

**2. address_delivery**
```{r}
data_clean %>% filter(is.na(address_delivery))   #in order to check which rows contain NA in the variable and decide how to manage it
data_clean <- data_clean %>%  
              mutate(address_delivery = replace(address_delivery,addresser_who == "giancarlo pagnoni", "villaggio badia,trav. seconda")) # I could see that "giancarlo pagnoni" 
                                                                                                                                         # has lot of deliveries: in this way I have modified the NA using the address of the deliveries with no NA.

# with data_clean <- data_clean %>% filter(!is.na(address_delivery))  I can delete the remaining NA rows
```
### QUESTION N.1: DO I HAVE A POSSIBILITY TO CHECK WHICH ADDRESSER APPEARS MORE TIME AND EVENTUALLY MODIFY IT WITH A CODE ? EX. using a FOR LOOP AND IF STATEMENT ?

**3. driver_code**
```{r}
data_clean %>% filter(is.na(driver_code))    #in order to check which rows contain NA in the variable and decide how to manage it
```
I do not need the rows with "fermo deposito" as address delivery, as it means these deliveries have been picked up directly on the factory
```{r}
data_clean <- data_clean %>% filter(data_clean$address_delivery != "fermo deposito")
```

**4. pickup_time**

I cannot recover the missing hours, but I can lead an analysis of the missing hours to eventually find out trends.
So, I create a dataframe with the missing hours
```{r}
NA_pickuptime_foranalysis <- data_clean %>%  mutate(pickup_time = replace(pickup_time,is.na(pickup_time), 0 )) %>% 
                 filter(pickup_time == 0)
```

After, I delete the rows containing the Missing hours.
```{r}
data_clean<- data_clean %>% filter(data_clean$pickup_time > 0)
```

----------------------------------------

# 3. FIXING DIFFERENCES OF SPELLING (on variables in which this is necessary)

**A.DISTRICT_DELIVERY**  
I create a variable to analyse 
```{r}
district_distinct <- group_by(data_clean, district_delivery) %>% summarise()  
```

### QUESTION N.2: IS THERE A WAY TO ANALYSE IF THERE IS AN EFFECTIVE CORRISPONDENCE BETWEEN THESE NAMES AND DISTRICTS IN BRESCIA? 
#### Example, if I obtain a dataset with all the district of Brescia and I try to compare them ?). Because I have 468 district and I cannot know every district of this city. In doing so I could have this done by R and manage just the district that do not find correspondence.
**Otherwise, I can work one per time but it would be an enormous waste of time**
```{r}
data_clean <- data_clean %>% 
  mutate(district_delivery = sub(pattern = "roe.*" , "roe' volciano", district_delivery))
```

**B.ADDRESS_DELIVERY**  
I create a variable to analyse 
```{r}
address_distinct <- group_by(data_clean, address_delivery) %>% summarise()  
```
In this case I have over 80k rows.
*First thing* I should do is to erase the number on the street that make the research too unusefully precise.
```{r}
data_clean <- data_clean %>%
              mutate(address_delivery= gsub("[[:digit:]]","",address_delivery))  
              # QUESTION N.3: MAYBE AVOID ALL THE PUNCTUATION WITH [:punct:] would work ?
```

### QUESTION N.4: IS THIS THE BEST WAY TO HANDLE ADDRESS_DELIVERY ? LOOKS A TRUE MESS

----------------------------------------

# 4. TURN ADDRESS INTO COORDINATES 

In this particular case I have Two possibilities of approach:

1) I *associate each district with its CAP* (the italian zip code) in order to perform my analysis within each CAP.  

In order to do so, I add to each row of "district_distinct" the name "Brescia" that will be useful for the Google geocoding system to recover the necessary data regarding each district.
```{r}
district_distinct <- district_distinct %>%  mutate(city = "Brescia") %>% unite(district_distinct, district_delivery, city, sep = "-" ) # IS THERE A SHORTER WAY ?

district_distinct <- as.character(district_distinct)

district_googleinfo <- geocode(location = district_distinct, output = c("more"))  # IT WORKS IF I TAKE THEM SINGULARLY, NOT TOGETHER (it gives me error WTF)

# AFTER THAT I WILL SELECT THE COLUMN "POSTAL_CODE" AND ASSOCIATE IT TO EACH DISTRICT IN MY DATA FRAME


revgeo <- revgeocode(location = as.numeric(..), output = c("more")) # TECHNICALLY I WILL NOT NEED THIS AS I HAVE ALREADY SET THE FUNCTION GEOCODE IN OUTPUT =  "MORE"

```


2) I **turn the addresses into coordinates** with the google geocoding as well, creating a variable address_lat and variable address_long.

In this case it is necessary to reduce the variable address_distinct to its minimum, ensuring to have optimally fixed the differences of spelling,  since the google geocoding system allows to make 2.5k queries per day.
```{r}
# SAME THAN BEFORE
```



# 5. WORKING WITH DATES 

_ Duplicate the variable "delivery_day" in order to keep it after I will have it split as following:

```{r}
data_clean <- data_clean %>% mutate(delivery_date = delivery_day)
```

_ Convert character string to Dates regarding the variables "dep_to_bs", "arr_to_bs", "delivery_day"
```{r}
data_clean <- data_clean %>% mutate(dep_to_bs = as.Date( x = dep_to_bs, format = "%d / %m / %y"),
                                    arr_to_bs = as.Date(x = arr_to_bs, format = "%d / %m / %y"),
                                    delivery_date = as.Date(x = delivery_date, format = "%d / %m / %y"))
```


_ Obtain the variable "weekday_deliv"
```{r}
data_clean <- data_clean %>% mutate(weekday_deliv = format(delivery_date, "%a"))  # FIX ISSUE: DAYS EXPRESSED IN ITALIAN
```



_ Split delivery_day column into 3 variables
```{r}
data_clean <- data_clean %>% separate(delivery_day, c("day_deliv", "month_deliv", "year_deliv"), sep = "/")
```



_ Trasform dates in a better format  (ISSUE: IT TURNS THEM INTO CHARACTER AGAIN)
```{r}
data_clean <- data_clean %>% mutate(dep_to_bs = format( x = dep_to_bs, format = "%d/%m/%y"),
                                    arr_to_bs = format(x = arr_to_bs, format = "%d/%m/%y"))
```




_ In case I will just work with March data, I will not need variable "month_deliv" and "year_deliv"
```{r}
data_clean <- select(data_clean, - month_deliv, - year_deliv)
```



# 6. WORKING WITH HOURS
_ Convert character string to time regarding the variable "pickup_time"
(The following section code needs to be improved)
```{r}
data_clean <- data_clean %>% mutate(pickup_time =  as.POSIXct(x = data_clean$pickup_time, format = "%H:%M")) %>% 
              mutate(pickup_time = gsub(pattern = "2018-05-16", replacement = "",x = pickup_time))                 #PROBABILY NOT THE BEST WAY AND THE                                                                                                                          PATTERN IS GOOD FOR TODAY, NOT AFTER.
data_clean <- data_clean %>% mutate(pickup_time = times(x = pickup_time))

```

_ Create a variable to perform operation with hours, converting each hour in minutes (past midnight?)
```{r}
# HOW TO DO IT ?
```


# 7.CONVERT NECESSARY VARIABLES INTO NUMERICS

```{r}

data_clean$weight_pack <- 
data_clean$num_pack <- as.numeric(data_clean$num_pack)
```


# SUMMARY: CREATE NEW DATAFRAMES USEFUL FOR MY ANALYSIS

```{r}
# TO BE COMPLETED DURING THE ANALYSIS
```




